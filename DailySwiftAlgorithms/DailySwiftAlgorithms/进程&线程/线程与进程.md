---
typora-root-url: ../shared
---

> 在面试中我们经常会被面试官问到线程是什么，进程是什么，以及二者之间的联系。然后我们大部分人的回答基本上都是如下：
>
> 线程是CPU独立运行和独立调度的基本单位（可以理解为一个进程中执行的代码片段），进程是资源分配的基本单位（进程是一块包含了某些资源的内存区域）。进程是线程的容器，真正完成代码执行的是线程，而进程则作为线程的执行环境。一个程序至少包含一个进程，一个进程至少包含一个线程，一个进程中的多个线程共享当前进程所拥有的资源。

##进程

进程是操作系统对一个正在运行的程序的抽象，可以简单理解为一个进程就是一个正在运行的程序。

逼格高一点，可以简单理解为每个程序就是一个字节块，而程序本身就是一个字节序列，然后操作系统让字节运行起来，让程序发挥作用。

逼格再高一点，怎么讲？程序本身就是磁盘上的一堆指令(也可能是一些静态数据)，然后CPU不间断的一条一条的执行程序中的指令，也就是说程序的代码和数据是系统内存中唯一的对象。

进程的创建

在操作系统中，我们的应用程序基本上都是以一种可执行文件的格式存储在磁盘上。

程序的运行是在内存中。

系统在创建或撤销进程时，都会为它分配或者回收资源，所谓的资源比如内存空间、I/O设备。

操作系统运行程序，首先就是将程序和所有的静态数据加载到内存中，加载到进程的地址空间中。

![加载：从程序到进程](/../进程&线程/加载：从程序到进程.png)

上图基本上就是程序加载到内存，操作系统所必须执行的一些操作的简单介绍。其中代码片段以及相关数据加载到内存的过程中，是一个懒加载的过程，具体的细节大家可以看一下虚拟内存相关的资料或者文章。



> *引申：在任何时刻，单核处理器系统都只能执行一个进程的代码。当我们启动并运行新程序时，就涉及到进程的切换（进程上下文切换），而进程的切换又涉及到了内核态和用户态，以及进程调度的相关知识，大家有兴趣的又有机会查资料看文档买书了。*

这里简单给个示例图：

![进程上下文切换](/../进程&线程/进程上下文切换.png)

以上简单粗浅的介绍了进程，可以看到进程在加载到内存的时候，确实分配了很多内存空间，且每个进程被分配的内存空间都是被隔离被保护的。那么线程就不分配资源了吗？

##线程

刚一开始讲到一个进程至少包含一个线程，也就是说一个进程可以包含多个线程，而处于同一个进程中的所有线程都运行在该进程的上下文当中，并共享了该进程的整个虚拟地址空间，也就是说共享了该进程虚拟地址空间的所有内容，包括代码，数据，堆，共享库，打开的文件。

从上面这段话，至少可以看出，线程之间的上下文切换不需要变换地址空间(或者说不需要切换当前使用的页表)，因为他们共享同一进程的虚拟地址空间。

> *引申：页表代表每一个进程的数据结构，用于记录进程虚拟内存到物理内存的映射关系，这部分有兴趣的可以看一下虚拟内存相关的资料；共享库的概念可以在程序的编译与链接相关资料里面查阅。*

那线程有什么，首先线程作为CPU独立运行和调度的基本单元，既然线程也是基本单元，那线程肯定也有它自己的上下文，线程的上下文中有什么？包含线程的ID，线程的栈，栈指针(栈指针指向栈顶元素的地址)，PC(程序计数器寄存器，存放将要执行的下一条指令在内存中的地址)，通用目的寄存器，条件码。

也就是说线程的创建，也是需要分配内存空间的，但是线程栈的空间开辟在它所属进程的堆区，也就是说线程虽然会分配内存但是它并没有独立的地址空间，不同的线程的栈位于同一进程地址空间的不同地址范围内。

可以看到，任意线程可以访问所属进程共享虚拟内存的任意位置，那么同属于一个进程的多个线程就可以同时访问(读|写)共享内存的同一个位置。这样的话就会出现我们在编程过程中经常遇到的线程安全的问题。

![多线程地址空间](/../进程&线程/多线程地址空间.png)

上图表示一个多线程的进程内存结构，可以看到有两个栈空间区域，它表示该进程拥有两个线程，且两个栈跨越了进程的地址空间。对于单线程的进程地址空间结构，可以在进程中的示例图中看到。

可以看到，对于进程和线程，我们所讲的堆，其实是针对进程而言的，而栈是针对线程而言的，线程中没有堆的的概念。而在进程加载的图(第一张图)中，很明显是一个单线程的进程，而往往在单独讲到进程的时候，也通常假设该进程是一个单线程进程。

##并发和并行

在单核CPU中，有且只有一个基址寄存器和一个界限寄存器。基址寄存器将虚拟地址转换为物理地址，界限寄存器确保地址在进程的地址空间的范围内。每个进程都有自己独立的内存空间，也就是说通过这个两个寄存器我们可以确定该进程的地址空间范围，并能够保证正确访问。

对于每个运行的程序，虚拟内存空间都是独立且不一样的，加载到内存中所对应的的物理地址肯定也是不一样的。如此的话，对于每一个运行的程序，基址寄存器和界限寄存器的值肯定也是不同的。也就是说单处理器系统在任何一个时刻，都只能执行一个程序的代码，结合线程作为任务运行和调度的基本单位，换言之单核CPU在任何时刻只能有一个线程在运行。另外，一个单核CPU中有且只有一个PC(程序计数器)，PC中存放下一条即将执行的指令，指令寄存器存放正在执行的指令，也就是说CPU一直不断的执行PC指向的指令，然后更新PC的值，使其指向下一条指令，进一步说明单核CPU在任何时刻只能单线程执行。

但是有些操作是不消耗CPU的，比如IO操作。当一个进程(假设为进程A)在执行IO操作，CPU等待IO操作完毕的过程中是闲置状态的。为了高效的利用CPU，这个时候我们可以加载其他进程(假设加载进程B)，执行其他进程(进程B)的相关操作。当上一个进程(进程A)的IO操作执行完毕后，CPU在将当前进程(进程B)切换成上一个进程(进程A)。整个过程可以通过第二章图看到整个过程。如果横过来看大概如下图：

![进程上下文切换](/../进程&线程/进程调度.png)

而多核CPU，每个一个核心都拥有一个PC寄存器，都有拥有自己独立的基址寄存器和界限寄存器，也就意味着多核CPU可以在同一时刻执行多条指令，且这些指令无需属于同一个进程。

换言之，单核CPU只能并发，而多核CPU才能做到并行执行。

##iOS多线程方案

| 技术方案    | 简介                                                         | 语言 | 线程生命周期 | 使用频率 |
| ----------- | ------------------------------------------------------------ | ---- | ------------ | -------- |
| Pthread     | 一套通用的多线程API,适用于Unix\Linux\Windows等系统，扩平台，可移植，使用难度大 | C    | 开发人员     | 极少     |
| NSThread    | 面向对象，简单易用，直接操作线程对象                         | OC   | 开发人员     | 偶尔     |
| GCD         | 旨在替代NSThread等线程技术，充分利用设备多核优势             | C    | 系统         | 经常     |
| NSOperation | 基于GCD，面向对象，增加取消、线程依赖等操作                  | OC   | 系统         | 经常     |

同步与异步主要区别在于能不能开启新线程

同步：在当前线程执行任务，不具备开启新线程的能力

异步：在新的线程执行任务，具备开启新线程的能力

并发与串行的主要区别在于任务的执行方式或者说是顺序

并发：多个任务并发(并行)执行，同一时刻可以多个任务同时进行

同步： 任务按顺序执行，同一时刻只能执行一个任务

|             | 并发队列                                        | 手动创建串行队列                         | 主队列                                          |
| ----------- | ----------------------------------------------- | ---------------------------------------- | ----------------------------------------------- |
| 同步(sync)  | 1. 没有开启新线程               2. 串行执行任务 | 1. 没有开启新线程        2. 串行执行任务 | 1.没有开启新线程    2.串行执行任务              |
| 异步(async) | 1. 开启新线程                 2. 并发执行任务   | 1. 开启新线程           2. 串行执行任务  | 1. 没有开启新线程               2. 串行执行任务 |

## 线程锁

### OSSpinLock 自旋锁(不安全)

1. OSSpinLock叫做“自旋锁”,等待锁的线程会处于忙等(busy-wait)的状态，一直占着CPU的资源

2. 目前已经不安全，可能会出现优先级翻转的问题

3. 如果等待锁的线程优先级比较高，它会一直占用着CPU资源，优先级低的线程就无法释放锁

   ```objective-c
   #import <libkern/OSAtomic.h>
   // 初始化
   OSSpinLock lock = OS_SPINLOCK_INIT;
   // 尝试加锁（如果需要等待就不加锁，直接返回fase,如果不需要等待就加锁，返回true）
   bool result = OSSpinLockTry(&lock);
   // 加锁
   OSSpinLockLock(&lock);
   // 解锁
   OSSpinLockUnlock(&lock);
   ```



### OSUnfairLock互斥锁

1. os_unfair_lock用于取代不安全的OSSPinLock，从iOS10开始支持

2. 从底层调用看，等待os_unfair_lock锁的线程会处于休眠状态，并非忙等

3. 运行效率最高

   ```objc
   #import <os/lock.h>
   // 初始化
   os_unfair_lock lock = OS_UNFAIR_LOCK_INIT;
   // 尝试加锁
   os_unfair_lock_trylock(&lock)
   // 加锁
   os_unfair_lock_lock(&lock)
   // 解锁
   os_unfair_lock_unlock(&lock)
   ```

### pthread_mutex

1. mutex叫做“互斥锁”,等待锁的线程会处于休眠状态

   ```objective-c
   // 初始化锁的属性
   pthread_mutexattr_t attr;
   pthread_mutexattr_init(&attr);
   pthread_mutexattr_settype(&attr, PTHREAD_MUTEX_NORMALL);
   // 初始化锁
   pthread_mutex_t mutex;
   pthread_mutex_init(&mutex, &attr);
   // 尝试加锁
   pthread_mutex_trylock(&mutex);
   // 加锁
   pthread_mutex_lock(&mutex);
   // 解锁
   pthread_mutex_unlock(&mutex);
   // 销毁相关资源
   pthread_mutexattr_destroy(&attr);
   pthread_mutex_destroy(&mutex);
   
   #define PTHREAD_MUTEX_NORMAL      0
   #define PTHREAD_MUTEX_ERRORCHECK  1
   #define PTHREAD_MUTEX_RECURSIVE   2
   #define PTHREAD_MUTEX_DEFAULT     PTHREAD_MUTEX_NORMAL
   ```

### NSLock、NSRecursiveLock

1. NSLock是对mutex普通锁的封装

2. NSRecursiveLock也是对mutex递归锁的封装，API跟NSLock基本一致

   ```objective-c
   @interface NSLock: NSObject<NSLocking>{
     -(BOOL)tryLock;
     -(BOOL)lockBeforeDate:(NSDate *)limit
   }
   @end
     
   @protocol NSLocking {
     - (void)lock;
     - (void)unlock;
   }
   @end
     
   // 初始化锁
   NSLock *lock = [[NSLock alloc] init];
   ```

   

### NSCondition

1. 条件锁

   ```objective-c
   @interface NSCondition: NSObject<NSLocking>
     - (void)wait;
     - (BOOL)waitUntilDate: (NSDate *)limit
     - (void)signal;
     - (void)broadcast;
   @end
   ```

### disptach_semaphore  

1. 信号量，可以用户控制最大并发数量

2. 信号量的初始值，可以用来控制线程并发访问的最大数量

3. 信号量的初始值为1，代表同时只允许1条线程访问资源，保证线程同步

   ```objective-c
   // 信号量的初始值
   int value = 1;
   // 初始化信号量
   dispatch_semaphore_t semaphore = dispatch_semaphore_create(value)
   // 如果信号量的值小于0，当前线程就会进入休眠等待，知道信号量的值大于0
   // 如果型号量的值大于0，就减一，然后往下执行后面的代码
   dispatch_semaphore_wait(semaphore, DISPATCH_TIME_FOREVER);
   // 让信号量的值加1
   dispatch_semaphore_signal(semaphore)
   ```


### @synchronized(互斥锁)

@synchronized是对mutex递归锁的封装，@synchronized(obj)内部会生成obj对应的递归锁，然后进行加锁、解锁操作。

```objc
@synchronized(obj) {
 //加锁的代码，大括号内才是被加锁的内容。而obj可以理解为该锁的唯一标志
}
```

### 性能排行

性能从高到低

**os_unfair_lock**(iOS10以后生效)

**OSSpinLock**(iOS10以后废弃)

**dispatch_semaphore**

**pthread_mutex**

**dispatch_queue(DISPATCH_QUEUE_SERIAL)**

**NSLock**

**NSCondition**

**pthread_mutex(recursive)**

**NSRecursiveLock**

**NSConditionLock**

**@synchronized**

### 自旋锁、互斥锁比较

#### 自旋锁

等待锁的线程会处于忙等(busy-wait)的状态，并不断尝试持有锁，一直占着CPU的资源。以下四种情况可以尝试使用自旋锁。

1. 预计线程等待锁的时间比较短
2. 加锁的代码（临界区）经常被调用，但竞争情况很少发生
3. CPU资源不紧张
4. 多核处理器

#### 互斥锁

等待锁的线程会处于休眠状态，不占用CPU资源。当持有锁的线程，释放锁以后，CPU会自动调度等待锁的线程。以下四种情况可以尝试使用互斥锁。

1. 预计线程等待锁的时间较长
2. 单核处理器
3. 临界区有IO操作
4. 临界区代码复杂或者循环量大
5. 临界区竞争非常激烈

### 多读单写

#### pthread_rwlock

等待锁的线程会进入休眠

```objective-c
// 初始化锁
pthread_rwlock_t lock;
pthread_rwlock_init(&lock, NULL);
// 读-加锁
pthread_rwlock_rdlock(&lock);
// 读尝试加锁
pthread_rwlock_tryrdlock(&lock);
// 写加锁
pthread_rwlock_wrlock(&lock);
// 写尝试加锁
pthread_rwlock_trywrlock(&lock);
// 解锁
pthread_rwlock_unlock(&lock);
// 销毁
pthread_rwlock_destroy(&lock);
```

#### dispatch_barrier_async

1. 这个函数传入的并发队列必须是自己通过`dispatch_queue_create`创建的

2. 如果传入的是一个串行或是一个全局的并发队列，那这个函数便等同于dispatch_async函数的效果

   ```objective-c
   // 初始化队列
   dispatch_queue_t queue = dispatch_queue_create('rw_queue', DISPATCH_QUEUE_CONCURRENT);
   // 读
   dispatch_async(queue, ^{
     //读
   });
   
   // 读代码执行完毕后，才会执行写的代码
   dispatch_barrier_async(queue, ^{
     //写
   });
   ```

   